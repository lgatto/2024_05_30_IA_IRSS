* Who am I

- Computational Biologist. Use/develop of DL in the CBIO lab.
- I am not an expert in IA.
- I have never used ChatGPT or any similar tools, and I'll tell you
  why!
- Actively following discussions and collecting articles about the
  topic.
- Will focus on ChatGTP and similar LLMs that are released by large
  and very powerful commenercial entities for wide public consumption.

* Reference

*On the Dangers of Stochastic Parrots: Can Language Models Be Too
Big?* by Emily M. Bender, Timnit Gebru, Angelina McMillan-Major,
Shmargaret Shmitchell

> The past 3 years of work in NLP have been characterized by the
> development and deployment of ever larger language models,
> especially for English. BERT, its variants, GPT-2/3, and others,
> most recently Switch-C, have pushed the boundaries of the possible
> both through architectural innovations and through sheer size. Using
> these pretrained models and the methodology of fine-tuning them for
> specific tasks, researchers have extended the state of the art on a
> wide array of tasks as measured by leaderboards on specific
> benchmarks for English. In this paper, we take a step back and ask:
> How big is too big? What are the possible risks associated with this
> technology and what paths are available for mitigating those risks?
> We provide recommendations including weighing the environmental and
> financial costs first, investing resources into curating and
> carefully documenting datasets rather than ingesting everything on
> the web, carrying out pre-development exercises evaluating how the
> planned approach fits into research and development goals and
> supports stakeholder values, and encouraging research directions
> beyond ever larger language models.

* When can I use ChatGPT?

** Given that

> LLMs have no notion of true or false, nor any understanding of what
> it is asked.

(And probabilistic, based on *biased training data* - see more about
this later)

** Use it if/when

1. You don't can about the validity of the results.
2. You are an expert in the field.

(Crédit: Yves Deville and Christine Jacqmot)

- They always hallucinate. It just happens so that sometimes, what is
  made up, is not wrong. I will come back to some of these points in
  the later /stochastic parrot/ section.

* At what cost?

** Human cost

Human cost is real and current. It is not a potential science-fiction
picture of AI vs humanity. Such a picture diminishes the current human
cost of AI, as is force-fed by big tech.

...

-> already marginalised communities to suffer the most.

** Environmental cost
...

-> already marginalised communities to suffer the most.

** Intellectual property

Credit and licensing of text, voice and images used for training.

* Stochastic parrot

* AI contamination

- Outlets are terminating journalist contract to replace them by AI.
- Independent writers are 'competing' against AI.

*Enshitification*

* 'ChatGPT' in research

- Reproducibility? [[https://www.nature.com/articles/d41586-024-01463-0][AlphaFold3 — why did Nature publish it without its
  code?]]
- Paper writing: paper mills
- Reviews: [[https://www.nature.com/articles/d41586-024-01106-4][Daily
  briefing: Signs that ChatGPT is polluting peer review]]
- [[https://arxiv.org/abs/2405.02150][The AI Review Lottery:
  Widespread AI-Assisted Peer Reviews Boost Paper Scores and
  Acceptance Rates]].

* ChatGPT in education?

> *Reminder*: use it if/when
> - You don't can about the validity of the results.
> - You are an expert in the field.

- What do we gain, what do we loose in using ChatGPT in education?
- Train students in using (not abusing) ChatGPT.
- Clear guidelines!

* Who benefits from ChatGTP/AI?

... being is force-fed by big tech!

- In search engines? Not the users.
- Facial recognition. Not the citizens.
- Microsoft Windows Recall. Not the employees.
- Automatic (meaningless) text and answer generation, that are being
  re-used for training.

-> Already marginalised communities to benefit the least. Privileged
communities to benefit the most.

- <2024-05-28 Tue> [[https://www.theguardian.com/technology/article/2024/may/28/openai-safety-council-chatgpt?CMP=Share_AndroidApp_Other][OpenAI forms safety council as it trains latest
  artificial intelligence model]]: The safety committee is filled with
  company insiders, including Sam Altman, the OpenAI CEO, and its
  chairman, Bret Taylor, and four OpenAI technical and policy
  experts. It also includes the board members Adam D’Angelo, who is
  the CEO of Quora, and Nicole Seligman, a former Sony general
  counsel.

* [[https://www.citationneeded.news/ai-isnt-useless/][AI isn't useless. But is it worth it?]]

AI can be kind of useful, but I'm not sure that a "kind of useful"
tool justifies the harm.
